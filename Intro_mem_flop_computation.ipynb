{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Iz_nZJSMmx7k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flopco-pytorch\n",
      "  Downloading flopco_pytorch-0.1.4-py3-none-any.whl.metadata (411 bytes)\n",
      "Downloading flopco_pytorch-0.1.4-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: flopco-pytorch\n",
      "Successfully installed flopco-pytorch-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install flopco-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Vn6LX-X_m-7h"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import flopco\n",
    "from flopco import FlopCo\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hPJysoxfoimk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(10)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eJxGU2sh-JX0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([20, 10])\n",
      "bias torch.Size([20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.nn.Linear(10, 20)\n",
    "for pname, p in l.named_parameters():\n",
    "  print(pname, p.shape)\n",
    "\n",
    "t = torch.randn((1, 20), dtype=torch.float16)\n",
    "t.dtype\n",
    "\n",
    "torch.finfo(torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7OyQYn78eyz"
   },
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7PeB4tyGu-RC"
   },
   "outputs": [],
   "source": [
    "def print_mem_usage(layer):\n",
    "  print('\\t Shape')\n",
    "  for name, tens in layer.named_parameters():\n",
    "    print(name + ':\\t', tuple(tens.shape))\n",
    "  print()\n",
    "\n",
    "  sum_bytes = 0\n",
    "  sum_params = 0\n",
    "  print('Parameters:')\n",
    "  print('\\tElems\\t Bits\\t\\tBytes\\t Kb\\t\\t Mb')\n",
    "  for name, tens in layer.named_parameters():\n",
    "    if tens.dtype is torch.float32:\n",
    "      bytes_in_dtype = 4\n",
    "    elif tens.dtype is torch.float64:\n",
    "      bytes_in_dtype = 8\n",
    "    else:\n",
    "      print(name + \" has unsupported type\")\n",
    "      continue\n",
    "    elems = tens.numel()\n",
    "    sum_params += elems\n",
    "    sum_bytes += elems * bytes_in_dtype\n",
    "\n",
    "    print(name + ':\\t',\n",
    "          elems, '\\t', elems * bytes_in_dtype * 8,\n",
    "          '\\t', elems * bytes_in_dtype,\n",
    "          '\\t', elems * bytes_in_dtype / 1024,\n",
    "          '\\t', round(elems * bytes_in_dtype / 1024 / 1024, 5))\n",
    "  print()\n",
    "  print('Buffers:')\n",
    "  print('\\tElems\\t Bits\\t\\tBytes\\t Kb\\t\\t Mb')\n",
    "  for name, tens in layer.named_buffers():\n",
    "    if tens.dtype is torch.float32:\n",
    "      bytes_in_dtype = 4\n",
    "    elif tens.dtype is torch.float64:\n",
    "      bytes_in_dtype = 8\n",
    "    else:\n",
    "      print(name + \" has unsupported type\")\n",
    "      continue\n",
    "    elems = tens.numel()\n",
    "    sum_params += elems\n",
    "    sum_bytes += elems * bytes_in_dtype\n",
    "\n",
    "    print(name + ':\\t',\n",
    "          elems, '\\t', elems * bytes_in_dtype * 8,\n",
    "          '\\t', elems * bytes_in_dtype,\n",
    "          '\\t', elems * bytes_in_dtype / 1024,\n",
    "          '\\t', round(elems * bytes_in_dtype / 1024 / 1024, 5))\n",
    "  print()\n",
    "  print('All:\\t',\n",
    "          sum_params, '\\t', sum_bytes * 8,\n",
    "          '\\t', sum_bytes,\n",
    "          '\\t', sum_bytes / 1024,\n",
    "          '\\t', round(sum_bytes / 1024 / 1024, 5))\n",
    "\n",
    "\n",
    "def gpu_mem_usage():\n",
    "    gc.collect()\n",
    "\n",
    "    if hasattr(torch.cuda, \"reset_peak_memory_stats\"):  # pytorch 1.4+\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    ma = torch.cuda.memory_allocated() / (1024 * 1024)\n",
    "    max_ma = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "    ca = torch.cuda.memory_reserved() / (1024 * 1024)\n",
    "    max_ca = torch.cuda.max_memory_reserved() / (1024 * 1024)\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"MA {round(ma, 4)} MB \\\n",
    "        Max_MA {round(max_ma, 4)} MB \\\n",
    "        CA {round(ca, 4)} MB \\\n",
    "        Max_CA {round(max_ca, 4)} MB \"\n",
    "        )\n",
    "    if hasattr(torch.cuda, \"reset_peak_memory_stats\"):  # pytorch 1.4+\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    return (ma, max_ma, ca, max_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgu1z43nyTOa"
   },
   "source": [
    "## Custom Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fIU56VKCnOLT"
   },
   "outputs": [],
   "source": [
    "class CustomLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    A module which applies a linear transformation\n",
    "    A common name is fully-connected layer, InnerProductLayer in caffe.\n",
    "\n",
    "    The module should work with 2D input of shape (n_samples, n_feature).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, n_out, dtype=torch.float32, device=None):\n",
    "        super().__init__()\n",
    "        if device is None:\n",
    "          device = torch.device(\"cpu\")\n",
    "        self.W = nn.Parameter(torch.Tensor(n_out, n_in).type(dtype).to(device))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_out).type(dtype).to(device))\n",
    "\n",
    "        # This is a nice initialization\n",
    "        stdv = 1./math.sqrt(n_in)\n",
    "        nn.init.uniform_(self.W, -stdv, stdv)\n",
    "        nn.init.uniform_(self.b, -stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.output = torch.add(torch.mm(input, self.W.T), self.b)\n",
    "\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8leYJqCFv_Er"
   },
   "outputs": [],
   "source": [
    "in_ch, out_ch = 100, 200 # example numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D3suMlox-dIX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical memory usage of linear layer in float32\n",
      "\t Shape\n",
      "W:\t (200, 100)\n",
      "b:\t (200,)\n",
      "\n",
      "Parameters:\n",
      "\tElems\t Bits\t\tBytes\t Kb\t\t Mb\n",
      "W:\t 20000 \t 640000 \t 80000 \t 78.125 \t 0.07629\n",
      "b:\t 200 \t 6400 \t 800 \t 0.78125 \t 0.00076\n",
      "\n",
      "Buffers:\n",
      "\tElems\t Bits\t\tBytes\t Kb\t\t Mb\n",
      "\n",
      "All:\t 20200 \t 646400 \t 80800 \t 78.90625 \t 0.07706\n"
     ]
    }
   ],
   "source": [
    "custom_linear_tf32 = CustomLinear(in_ch, out_ch, dtype=torch.float32, device=device_cpu)\n",
    "print('Theoretical memory usage of linear layer in float32')\n",
    "print_mem_usage(custom_linear_tf32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0D1gEAJC-zQv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical memory usage of linear layer in float64\n",
      "\t Shape\n",
      "W:\t (200, 100)\n",
      "b:\t (200,)\n",
      "\n",
      "Parameters:\n",
      "\tElems\t Bits\t\tBytes\t Kb\t\t Mb\n",
      "W:\t 20000 \t 1280000 \t 160000 \t 156.25 \t 0.15259\n",
      "b:\t 200 \t 12800 \t 1600 \t 1.5625 \t 0.00153\n",
      "\n",
      "Buffers:\n",
      "\tElems\t Bits\t\tBytes\t Kb\t\t Mb\n",
      "\n",
      "All:\t 20200 \t 1292800 \t 161600 \t 157.8125 \t 0.15411\n"
     ]
    }
   ],
   "source": [
    "custom_linear_tf64 = CustomLinear(in_ch, out_ch, dtype=torch.float64, device=device_cpu)\n",
    "print('Theoretical memory usage of linear layer in float64')\n",
    "print_mem_usage(custom_linear_tf64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlMmmQge85Mi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical memory usage\n",
      "\t Shape\n",
      "W:\t (200, 100)\n",
      "b:\t (200,)\n",
      "\n",
      "Parameters:\n",
      "\tElems\t Bits\t\tBytes\t Kb\t\t Mb\n",
      "W:\t 20000 \t 640000 \t 80000 \t 78.125 \t 0.07629\n",
      "b:\t 200 \t 6400 \t 800 \t 0.78125 \t 0.00076\n",
      "\n",
      "Buffers:\n",
      "\tElems\t Bits\t\tBytes\t Kb\t\t Mb\n",
      "\n",
      "All:\t 20200 \t 646400 \t 80800 \t 78.90625 \t 0.07706\n",
      "\n",
      "Practical memory usage\n",
      "MA 0.0776 MB         Max_MA 0.0776 MB         CA 2.0 MB         Max_CA 2.0 MB \n"
     ]
    }
   ],
   "source": [
    "in_channel, out_channel = in_ch, out_ch\n",
    "custom_linear = CustomLinear(in_channel, out_channel, device=device)\n",
    "\n",
    "print(\"Theoretical memory usage\")\n",
    "print_mem_usage(custom_linear)\n",
    "print()\n",
    "print(\"Practical memory usage\")\n",
    "gpu_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyPGp94HBP2X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pysYq9gKCck-"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch_linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mtorch_linear\u001b[49m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m torch_linear\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch_linear' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "(torch_linear.weight.numel()*4 + torch_linear.bias.numel()*4)/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnlYksTQldMl"
   },
   "outputs": [],
   "source": [
    "inp = torch.randn(1,in_channel).to(device)\n",
    "\n",
    "torch_linear = nn.Linear(in_channel, out_channel).to(device)\n",
    "torch_linear.weight = custom_linear.W\n",
    "torch_linear.bias = custom_linear.b\n",
    "\n",
    "torch.linalg.norm(custom_linear(inp) - torch_linear(inp)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYajAVVYyYXI"
   },
   "source": [
    "## Custom Conv2d layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "802qT3HfshpC"
   },
   "outputs": [],
   "source": [
    "class CustomConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 dtype=torch.float32, device=None):\n",
    "        super().__init__()\n",
    "        if device is None:\n",
    "          device = torch.device(\"cpu\")\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        if isinstance(kernel_size, int):\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.conv = nn.Parameter(torch.Tensor(self.out_channels, self.in_channels, *self.kernel_size).type(dtype).to(device))\n",
    "        self.b = nn.Parameter(torch.Tensor(self.out_channels).type(dtype).to(device))\n",
    "\n",
    "        # This is a nice initialization\n",
    "        stdv = 1./math.sqrt(self.in_channels)\n",
    "        nn.init.uniform_(self.conv, -stdv, stdv)\n",
    "        nn.init.uniform_(self.b, -stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.conv2d(x, self.conv, self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVlttNbswW3P"
   },
   "outputs": [],
   "source": [
    "in_channel, out_channel = 5, 10\n",
    "h, w = 300, 300\n",
    "kernel_size = 3\n",
    "inp = torch.randn(1, in_channel, h, w).to(device)\n",
    "custom_conv = CustomConv2d(in_channel, out_channel, kernel_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKd2WPNLwa8l"
   },
   "outputs": [],
   "source": [
    "torch_conv = nn.Conv2d(in_channel, out_channel, kernel_size).to(device)\n",
    "torch_conv.weight = custom_conv.conv\n",
    "torch_conv.bias = custom_conv.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv49FVXcw3-N"
   },
   "outputs": [],
   "source": [
    "torch.linalg.norm(custom_conv(inp) - torch_conv(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QwzW7LHzw-u"
   },
   "outputs": [],
   "source": [
    "print_mem_usage(custom_conv)\n",
    "print()\n",
    "print_mem_usage(torch_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAY1ycubyHPF"
   },
   "outputs": [],
   "source": [
    "nn.Conv2d?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJxivsSdYGEp"
   },
   "source": [
    "# FLOP and Time estimation and dependence on input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTDo53c8YFGJ"
   },
   "outputs": [],
   "source": [
    "in_channel, out_channel = 3, 21\n",
    "h, w = 300, 300\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3A8nHFTQZSGH"
   },
   "outputs": [],
   "source": [
    "torch_conv = nn.Conv2d(in_channel, out_channel, kernel_size).to(device_cpu)\n",
    "stats = FlopCo(torch_conv,\n",
    "               img_size = (1, in_channel, h, w),\n",
    "               device = device_cpu,\n",
    "               instances = [nn.Conv2d])\n",
    "\n",
    "print(\"MFlop:\\t\", stats.flops[''][0]/10e6)\n",
    "print(\"Parameters:\\t\", stats.params[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53LEUikPcolZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bps95hZZsSif"
   },
   "source": [
    "## Linear Flop estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqSERKcveE8m"
   },
   "outputs": [],
   "source": [
    "flops = []\n",
    "for in_chan in range(200,4000,200):\n",
    "  torch_linear = nn.Linear(in_chan, 1000).to(device_cpu)\n",
    "  stats = FlopCo(torch_linear,\n",
    "                img_size = (1, in_chan),\n",
    "                device = device_cpu,\n",
    "                instances = [nn.Linear])\n",
    "  flops.append(stats.flops[''][0]/10e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9QkVkYGecgc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.plot(list(range(200,4000,200)), flops, '*')\n",
    "plt.xlabel('vector length')\n",
    "plt.ylabel('MFlop')\n",
    "plt.title('MFlop vs vector length for Linear layer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-X9iFH6_sMCi"
   },
   "source": [
    "## Convd2d Flop estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umXJuBdCb9-f"
   },
   "outputs": [],
   "source": [
    "torch_conv = nn.Conv2d(in_channel, out_channel, kernel_size).to(device_cpu)\n",
    "flops = []\n",
    "for h in tqdm(range(100,2000,100)):\n",
    "  stats = FlopCo(torch_conv,\n",
    "                img_size = (1, in_channel, h, h),\n",
    "                device = device_cpu,\n",
    "                instances = [nn.Conv2d])\n",
    "  flops.append(stats.flops[''][0]/10e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vShwMhMUcnQT"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(100,2000,100)), flops, '*')\n",
    "plt.xlabel('weight/height of \"image\"')\n",
    "plt.ylabel('MFlop')\n",
    "plt.title('MFlop vs weight for Conv2d layer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYbM2FygsFoN"
   },
   "source": [
    "## Convd2d time estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJOHGJIjjYv1"
   },
   "outputs": [],
   "source": [
    "torch_conv = nn.Conv2d(in_channel, out_channel, kernel_size).to(device_cpu)\n",
    "time_empir = []\n",
    "warmups = 5\n",
    "repeat = 45\n",
    "for h in tqdm(range(100,2000,100)):\n",
    "  time_h = []\n",
    "  input = torch.randn(1, in_channel, h, h).to(device_cpu)\n",
    "  for _ in range(warmups):\n",
    "    tmp = torch_conv(input)\n",
    "  for _ in range(repeat):\n",
    "    start = time.time()\n",
    "    tmp = torch_conv(input)\n",
    "    end = time.time()\n",
    "    time_h.append(end-start)\n",
    "  time_empir.append(statistics.mean(time_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xxi7lyXZjaLQ"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(100,2000,100)), time_empir, '*')\n",
    "plt.xlabel('weight/height of \"image\"')\n",
    "plt.ylabel('Time, s')\n",
    "plt.title('Time vs weight for Conv2d layer on CPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1ku-AwByNwT"
   },
   "outputs": [],
   "source": [
    "torch_conv = nn.Conv2d(in_channel, out_channel, kernel_size).to(device)\n",
    "time_empir = []\n",
    "warmups = 5\n",
    "repeat = 30\n",
    "for h in tqdm(range(100,2000,100)):\n",
    "  time_h = []\n",
    "  input = torch.randn(10, in_channel, h, h).to(device)\n",
    "  for _ in range(warmups):\n",
    "    tmp = torch_conv(input)\n",
    "  for _ in range(repeat):\n",
    "    start = time.time()\n",
    "    tmp = torch_conv(input)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    time_h.append(end-start)\n",
    "  time_empir.append(statistics.mean(time_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqxKvD7QyNwU"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(100,2000,100)), time_empir, '*')\n",
    "plt.xlabel('weight/height of \"image\"')\n",
    "plt.ylabel('Time, s')\n",
    "plt.title('Time vs weight for Conv2d layer on GPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjbmdlWVsAlz"
   },
   "source": [
    "## ReLU time estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oAmaeF0qZUA"
   },
   "outputs": [],
   "source": [
    "torch_relu = nn.ReLU().to(device_cpu)\n",
    "time_empir = []\n",
    "vector_len = []\n",
    "warmups = 5\n",
    "repeat = 150\n",
    "for h in tqdm(range(100,2000,100)):\n",
    "  time_h = []\n",
    "  input = torch.randn(1, h*10000).to(device_cpu)\n",
    "  for _ in range(warmups):\n",
    "    tmp = torch_relu(input)\n",
    "  for _ in range(repeat):\n",
    "    start = time.time()\n",
    "    tmp = torch_relu(input)\n",
    "    end = time.time()\n",
    "    time_h.append(end-start)\n",
    "  time_empir.append(statistics.mean(time_h))\n",
    "  vector_len.append(input.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uyhn3XTqngU"
   },
   "outputs": [],
   "source": [
    "plt.plot(vector_len, time_empir, '*')\n",
    "plt.xlabel('length of vector')\n",
    "plt.ylabel('Time, s')\n",
    "plt.title('Time vs length of vector for ReLU layer on CPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ3wsGRSyePr"
   },
   "source": [
    "## Custom BatchNorm2d layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40r_okFBw6vl"
   },
   "outputs": [],
   "source": [
    "class CustomBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "\n",
    "    def forward(self, input):\n",
    "        momentum = self.momentum\n",
    "\n",
    "        # calculate running estimates\n",
    "        if self.training:\n",
    "            mean = input.mean([0, 2, 3])\n",
    "            # use biased var in train\n",
    "            var = input.var([0, 2, 3], unbiased=False)\n",
    "            n = input.numel() / input.size(1)\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = momentum * mean \\\n",
    "                                + (1 - momentum) * self.running_mean\n",
    "                # update running_var with unbiased var\n",
    "                self.running_var = momentum * var * n / (n - 1) \\\n",
    "                                + (1 - momentum) * self.running_var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        input = (input - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwkqA8W2yuim"
   },
   "outputs": [],
   "source": [
    "n_channels = 100\n",
    "custom_bn = CustomBatchNorm2d(n_channels)\n",
    "torch_bn = nn.BatchNorm2d(n_channels, affine=False)\n",
    "\n",
    "inp = torch.randn(20, n_channels, 25, 25, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArWc8EJAz918"
   },
   "outputs": [],
   "source": [
    "torch.linalg.norm(custom_bn(inp) - torch_bn(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mB3hq55qTxT7"
   },
   "outputs": [],
   "source": [
    "print_mem_usage(custom_bn)\n",
    "print()\n",
    "print_mem_usage(torch_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VX7nbn99s79p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PL_F4p712B8"
   },
   "source": [
    "## Linear+ReLU flops and time estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQr0uP_V12CE"
   },
   "outputs": [],
   "source": [
    "\n",
    "time_empir = []\n",
    "flops = []\n",
    "all_stats = []\n",
    "warmups = 5\n",
    "repeat = 45\n",
    "for in_chan in range(200,4000,200):\n",
    "  time_h = []\n",
    "  torch_linear = nn.Linear(in_chan, 1000).to(device_cpu)\n",
    "  relu = nn.ReLU()\n",
    "  tiny_model = nn.Sequential(torch_linear, relu)\n",
    "  input = torch.randn(1, in_chan).to(device_cpu)\n",
    "\n",
    "  for _ in range(warmups):\n",
    "    tmp = tiny_model(input)\n",
    "  for _ in range(repeat):\n",
    "    start = time.time()\n",
    "    tmp = tiny_model(input)\n",
    "    end = time.time()\n",
    "    time_h.append(end-start)\n",
    "  time_empir.append(statistics.mean(time_h))\n",
    "\n",
    "  stats = FlopCo(tiny_model,\n",
    "                img_size = (1, in_chan),\n",
    "                device = device_cpu,\n",
    "                instances = [nn.Linear, nn.ReLU])\n",
    "  flops.append(stats.total_flops/10e6)\n",
    "  all_stats.append(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXm2cgoG12CF"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(200,4000,200)), flops, '*')\n",
    "plt.xlabel('input size')\n",
    "plt.ylabel('MFlop')\n",
    "plt.title('MFlop vs weight for Linear+ReLU layers on CPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHp9gmBs6SqR"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(200,4000,200)), time_empir, '*')\n",
    "plt.xlabel('input size')\n",
    "plt.ylabel('Time, s')\n",
    "plt.title('Time vs weight for Linear+ReLU layers on CPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtXAknzo7bOa"
   },
   "source": [
    "## Conv2d+BN+ReLU flops and time estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVgVAv8m7bOa"
   },
   "outputs": [],
   "source": [
    "in_channel, out_channel = 3, 21\n",
    "h, w = 300, 300\n",
    "kernel_size = 3\n",
    "\n",
    "time_empir = []\n",
    "flops = []\n",
    "all_stats = []\n",
    "warmups = 5\n",
    "repeat = 25\n",
    "for h in tqdm(range(100,2000,100)):\n",
    "  time_h = []\n",
    "  torch_conv = nn.Conv2d(in_channel, out_channel, kernel_size).to(device_cpu)\n",
    "  torch_bn = nn.BatchNorm2d(out_channel)\n",
    "  relu = nn.ReLU()\n",
    "  tiny_model = nn.Sequential(torch_conv, torch_bn, relu)\n",
    "  input = torch.randn(1, in_channel, h, h).to(device_cpu)\n",
    "\n",
    "  for _ in range(warmups):\n",
    "    tmp = tiny_model(input)\n",
    "  for _ in range(repeat):\n",
    "    start = time.time()\n",
    "    tmp = tiny_model(input)\n",
    "    end = time.time()\n",
    "    time_h.append(end-start)\n",
    "  time_empir.append(statistics.mean(time_h))\n",
    "\n",
    "  stats = FlopCo(tiny_model,\n",
    "                img_size = input.shape,\n",
    "                device = device_cpu,\n",
    "                instances = [nn.Conv2d, nn.BatchNorm2d, nn.ReLU])\n",
    "  flops.append(stats.total_flops/10e6)\n",
    "  all_stats.append(stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTf4s3Fe7bOa"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(100,2000,100)), flops, '*')\n",
    "plt.xlabel('input size')\n",
    "plt.ylabel('MFlop')\n",
    "plt.title('MFlop vs weight for Conv2d+BN+ReLU layers on CPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOc_k1wL7bOa"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(100,2000,100)), time_empir, '*')\n",
    "plt.xlabel('input size')\n",
    "plt.ylabel('Time, s')\n",
    "plt.title('Time vs weight for Conv2d+BN+ReLU layers on CPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_oFuBGr8-DB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
