{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "235631d7ddcba27eef6ed79a6e6ea1a3",
     "grade": false,
     "grade_id": "cell-cce492dd33469524",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### How to fill this notebook?\n",
    "\n",
    "Please replace\n",
    "```py\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "or\n",
    "\n",
    "``YOUR ANSWER HERE``\n",
    "\n",
    "by your answer to the questions asked. \\\n",
    "For most of the tasks, you will find a cell with basic tests.  They are mainly placeholders for the additional ones we will run for your evaluation. \\\n",
    "Feel free to add cells if you need. Please add comments or text cells to explain your reasoning; a wrong result with good explanation will still get some points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flopco-pytorch in /home/mkherraz001/miniconda3/envs/torch/lib/python3.12/site-packages (0.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install flopco-pytorch\n",
    "import hashlib\n",
    "import flopco\n",
    "from flopco import FlopCo\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9479b19b437cddd6d2246dded85e0af5",
     "grade": false,
     "grade_id": "cell-56551a2514bd5ba5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1 - Bytes [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977923228312\n"
     ]
    }
   ],
   "source": [
    "name = \"\" # Enter your name here # @critical : remove this line before commit to public repo\n",
    "randseed_str = hashlib.sha256(name.encode('utf-8')).hexdigest()\n",
    "randseed = int(randseed_str[:10], 16)\n",
    "print(randseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8730fc6f846d977579f086e4eb598de",
     "grade": false,
     "grade_id": "cell-990d10aa56d072ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Convert the pseudo-random number generated to KB and MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5a315d03bfb53a175985cbc3014237a",
     "grade": false,
     "grade_id": "cell-1eb73ba65bed94c9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bytes: 977923228312\n",
      "Number of KB: 955003152.6484375\n",
      "Number of MB: 932620.2662582397\n"
     ]
    }
   ],
   "source": [
    "n_bytes = randseed\n",
    "n_KB = n_bytes / 1024\n",
    "n_MB = n_bytes / (1024 ** 2)\n",
    "\n",
    "print(f\"Number of bytes: {n_bytes}\")\n",
    "print(f\"Number of KB: {n_KB}\")\n",
    "print(f\"Number of MB: {n_MB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b6dbec3b658ec59c78166a4922f23ac",
     "grade": true,
     "grade_id": "cell-f17f500e03850e33",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert n_KB != 0\n",
    "assert n_MB != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f6a15a06f9b6160807a2533d2c3e7a9",
     "grade": false,
     "grade_id": "cell-bef0999453636b4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 2 - FLOPs and MACs [3 points]\n",
    "\n",
    "Consider a convolutional layer, such that\n",
    "\n",
    "- $H_{in} = W_{in} = 11$\n",
    "- $k_{in} = k_{out} = 3$\n",
    "- $C_{in} = C_{out} = 16$\n",
    "\n",
    "Assume $H_{out} = W_{out} = 9$\n",
    "\n",
    "a) How much padding is needed on both spatial dimensions $H$ and $W$? [1 point]\n",
    "\n",
    "b) How many FLOP and MAC are performed for standard convolution? [1 point]\n",
    "\n",
    "c) How many FLOP and MAC are performed for depth-wise convolution? [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "991cda06a8ce6b59954fff26d1de5525",
     "grade": true,
     "grade_id": "cell-881d8c6222a36816",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## My answer\n",
    "\n",
    "#### a) How much padding is needed on both spatial dimensions $H$ and $W$? [1 point]\n",
    "\n",
    "To determine the padding needed, we use the formula for the output dimension of a convolutional layer:\n",
    "\n",
    "$$ H_{out} = \\frac{H_{in} + 2 \\times \\text{padding} - \\text{kernel size}}{\\text{stride}} + 1 $$\n",
    "\n",
    "Given:\n",
    "- $H_{in} = 11$\n",
    "- $\\text{kernel size} = 3$\n",
    "- $\\text{stride} = 1$\n",
    "- $H_{out} = 9$\n",
    "\n",
    "Plugging in the values:\n",
    "\n",
    "$$ 9 = \\frac{11 + 2 \\times \\text{padding} - 3}{1} + 1 $$\n",
    "\n",
    "Solving for padding:\n",
    "\n",
    "$$ 9 - 1 = 11 + 2 \\times \\text{padding} - 3 $$\n",
    "$$ 8 = 8 + 2 \\times \\text{padding} $$\n",
    "$$ 2 \\times \\text{padding} = 2 $$\n",
    "$$ \\text{padding} = 1 $$\n",
    "\n",
    "So, the padding needed on both spatial dimensions $H$ and $W$ is 1.\n",
    "\n",
    "#### b) How many FLOP and MAC are performed for standard convolution? [1 point]\n",
    "\n",
    "For standard convolution, the number of FLOPs (Floating Point Operations) and MACs (Multiply-Accumulate Operations) can be calculated as follows:\n",
    "\n",
    "- Each output element requires $C_{in} \\times \\text{kernel size}^2$ MACs.\n",
    "- There are $H_{out} \\times W_{out} \\times C_{out}$ output elements.\n",
    "\n",
    "Given:\n",
    "- $C_{in} = 16$\n",
    "- $\\text{kernel size} = 3$\n",
    "- $H_{out} = W_{out} = 9$\n",
    "- $C_{out} = 16$\n",
    "\n",
    "Number of MACs per output element:\n",
    "\n",
    "$$ \\text{MACs per output element} = 16 \\times 3 \\times 3 = 144 $$\n",
    "\n",
    "Total number of MACs:\n",
    "\n",
    "$$ \\text{Total MACs} = 9 \\times 9 \\times 16 \\times 144 = 186,624 $$\n",
    "\n",
    "Since each MAC consists of one multiplication and one addition, the number of FLOPs is twice the number of MACs:\n",
    "\n",
    "$$ \\text{Total FLOPs} = 2 \\times 186,624 = 373,248 $$\n",
    "\n",
    "#### c) How many FLOP and MAC are performed for depth-wise convolution? [1 point]\n",
    "\n",
    "For depth-wise convolution, each input channel is convolved with its own set of filters. The number of MACs and FLOPs can be calculated as follows:\n",
    "\n",
    "- Each output element requires $\\text{kernel size}^2$ MACs.\n",
    "- There are $H_{out} \\times W_{out} \\times C_{out}$ output elements.\n",
    "\n",
    "Given:\n",
    "- $\\text{kernel size} = 3$\n",
    "- $H_{out} = W_{out} = 9$\n",
    "- $C_{out} = 16$\n",
    "\n",
    "Number of MACs per output element:\n",
    "\n",
    "$$ \\text{MACs per output element} = 3 \\times 3 = 9 $$\n",
    "\n",
    "Total number of MACs:\n",
    "\n",
    "$$ \\text{Total MACs} = 9 \\times 9 \\times 16 \\times 9 = 11,664 $$\n",
    "\n",
    "Since each MAC consists of one multiplication and one addition, the number of FLOPs is twice the number of MACs:\n",
    "\n",
    "$$ \\text{Total FLOPs} = 2 \\times 11,664 = 23,328 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a36e953f40b3c95b84367fa0ea4ac41",
     "grade": false,
     "grade_id": "cell-23c73abac45e037c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 3 [2 points]\n",
    "\n",
    "Consider an input image of size $x$ is $(c, h, w)$ and a batch size $b$.\n",
    "\n",
    "Compute the number of FLOP for BatchNorm2d(x) (in training mode)\n",
    "\n",
    "Note: Consider that FLOP(division operation) = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fbec632d465fd0d60f8e295825ae431",
     "grade": false,
     "grade_id": "cell-5c4ca1bff1667e2a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flops_batchnorm(img):\n",
    "\tb, c, h, w = img.shape\n",
    "\t\n",
    "\t# Calculate the number of elements\n",
    "\tnum_elements = b * c * h * w\n",
    "\t\n",
    "\t# Mean calculation: sum and division\n",
    "\tflops_mean = num_elements + c * h * w * 4  # sum + division\n",
    "\t\n",
    "\t# Variance calculation: subtraction, square, sum, and division\n",
    "\tflops_variance = num_elements + num_elements + c * h * w * 4  # subtraction + square + sum + division\n",
    "\t\n",
    "\t# Normalization: subtraction and division\n",
    "\tflops_normalization = num_elements * 2  # subtraction + division\n",
    "\t\n",
    "\t# Scaling and shifting: multiplication and addition\n",
    "\tflops_scaling_shifting = num_elements * 2  # multiplication + addition\n",
    "\t\n",
    "\t# Total FLOPs\n",
    "\ttotal_flops = flops_mean + flops_variance + flops_normalization + flops_scaling_shifting\n",
    "\t\n",
    "\treturn total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e0fc2007b0c28b4c540133baf53f232",
     "grade": true,
     "grade_id": "cell-3946f981df4b26ce",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs for batch normalization: 5227200\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m torch_bn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(c, affine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mFlopCo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_bn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m               \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m               \u001b[49m\u001b[43minstances\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNorm2d\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(stats\u001b[38;5;241m.\u001b[39mflops)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"MFlop:\\t\", stats.flops[''][0]/10e6)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(\"Parameters:\\t\", stats.params[''])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/flopco/flopco.py:70\u001b[0m, in \u001b[0;36mFlopCo.__init__\u001b[0;34m(self, model, img_size, custom_tensor, device, instances)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_flops \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mNone\u001b[39;00m,\\\n\u001b[1;32m     62\u001b[0m                                   {k: \u001b[38;5;28msum\u001b[39m(v)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_flops\\\n\u001b[1;32m     63\u001b[0m                                    \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflops\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_macs \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mNone\u001b[39;00m,\\\n\u001b[1;32m     66\u001b[0m                           {k: \u001b[38;5;28msum\u001b[39m(v)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_macs\\\n\u001b[1;32m     67\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmacs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_params \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mNone\u001b[39;00m,\\\n\u001b[0;32m---> 70\u001b[0m                   {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_params\u001b[49m\\\n\u001b[1;32m     71\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m     74\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "b = 4\n",
    "c = 3\n",
    "h = 220\n",
    "w = 220\n",
    "img = torch.randn(b, c, h, w)\n",
    "\n",
    "print(f\"FLOPs for batch normalization: {flops_batchnorm(img)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "assert flops_batchnorm(img) != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9054e60843f6a4f8422b560a5307109e",
     "grade": false,
     "grade_id": "cell-457caf06211505b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 4 [1 point]\n",
    "\n",
    "Compute the number of FLOP for Parametric ReLU (PReLU):)\n",
    "\n",
    "$$\\operatorname{PReLU}\n",
    "\\left(y_{i}\\right)= \\begin{cases}y_{i}, & \\text { if } y_{i}>0 \\\\ a_{i} y_{i}, & \\text { if } y_{i} \\leq 0\\end{cases}$$\n",
    "\n",
    "Note: do not count comparisons as operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e0a7b255ae7826d43f029adacd0caa0",
     "grade": false,
     "grade_id": "cell-a1b3a99587b34ad9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flops_prelu(x):\n",
    "    b, n = x.shape\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e1b851a22e2a03d2ded80c9c1be6a6c",
     "grade": true,
     "grade_id": "cell-94c32bc48022b4be",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(b, n)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mflops_prelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mflops_prelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m b, n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "b = 4\n",
    "n = 128\n",
    "x = torch.randn(b, n)\n",
    "assert flops_prelu(x) != 0 or torch.all(x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6bd1c41b391ebe7efb3c1f078a44f5b4",
     "grade": false,
     "grade_id": "cell-879d4d98ceb5d860",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 5 [2 points]\n",
    "\n",
    "Compute the number of FLOP for the Softmax function:\n",
    "\n",
    "\n",
    "$$\\operatorname{Softmax}\\left(x_{i}\\right)=\\frac{\\exp \\left(x_{i}\\right)}{\\sum_{j} \\exp \\left(x_{j}\\right)}.$$\n",
    "\n",
    "Note: consider that $\\operatorname{FLOP}(\\operatorname{exp}) = 40$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "110b3318cc0e20fbc79b9734715d0243",
     "grade": false,
     "grade_id": "cell-af1acc225a488284",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flops_softmax(x):\n",
    "    b, n = x.shape\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c73b84f844e14ae9703a3758a651d2b",
     "grade": true,
     "grade_id": "cell-52de12f07106e559",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# do not modify\n",
    "b = 4\n",
    "n = 32\n",
    "x = torch.zeros(b, n)\n",
    "assert flops_softmax(x) != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "950672b3c7571d535d757d64c500d59a",
     "grade": false,
     "grade_id": "cell-0cefdf49c9714fb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 5 - Arithmetic intensity [6 points]\n",
    "\n",
    "Consider the following model.\\\n",
    "Assuming batch size 1,\n",
    "- how much FLOP does it perform? [1 point]\n",
    "- how much memory is transferred? [1 point]\n",
    "- is it memory or compute bound? [1 point]\n",
    "\n",
    "*Note: notice there is no bias*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a65af3edb541abd89a739cd8a222e6a3",
     "grade": false,
     "grade_id": "cell-39919b89707a53f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.PReLU(),\n",
    "    nn.Linear(64, 32, bias=False)\n",
    ").to(device)\n",
    "\n",
    "inputs = torch.randn(1, 64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a8d8a3471e08d7d584604134b1cb14d",
     "grade": false,
     "grade_id": "cell-e3cb7d52e37b286e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_flops = ...\n",
    "n_mem = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41a03afd5003e06b1ae28beb611d2903",
     "grade": true,
     "grade_id": "cell-f000150f173558b6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7763fe4e5d83812ed873c7698133050",
     "grade": true,
     "grade_id": "cell-a0efc40da2b3d0f3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert n_flops != 0\n",
    "assert n_mem != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49b08427bfe358c4183fe54f7e1226a7",
     "grade": false,
     "grade_id": "cell-edb12e983a403316",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Plot the arithmetic intensity for different batch sizes. [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c021f9ab89e2b15bbcf08b05ceaf198f",
     "grade": true,
     "grade_id": "cell-ed947b3a84de12f6",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64]\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1457c2012bccdc1ebee39db2c9e3dcca",
     "grade": false,
     "grade_id": "cell-728937adc55c9e6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "What is the optimal batch size for your gpu? [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f72a05eca7150bb439a627892c1f9d5d",
     "grade": true,
     "grade_id": "cell-f30f7cad60d78829",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61fbe0bd8735f05f9e9ac91afe48dc13",
     "grade": false,
     "grade_id": "cell-f8732bcd6b86fcee",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Bonus (not mandatory) [2 points]\n",
    "\n",
    "Answer all questions in task 5 again, but considering that the PReLU and the Linear are fused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eda9ab936077b336779346c423108420",
     "grade": false,
     "grade_id": "cell-fef8ab2d14c1fd64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 6 - Memory\n",
    "\n",
    "Consider this vision model. We will try to estimate its memory usage.\n",
    "\n",
    "How many parameters does it have? How much memory do the parameters take up? [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d6466283dee26b758740a4751a90a70",
     "grade": false,
     "grade_id": "cell-805eeae792eebaec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.create_model(\"convnextv2_large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4dda3122c66b0ad379f65ef0ac62dd8",
     "grade": false,
     "grade_id": "cell-d3bacd71a6cd40c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_params = ...\n",
    "n_memory = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fb5acb489d48be03fe385333d44f3ef",
     "grade": true,
     "grade_id": "cell-6f0f6e60ee7fbacb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert n_params > 0\n",
    "assert n_memory > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "defbc3079729f63e7f92e57230447fda",
     "grade": false,
     "grade_id": "cell-257f1eb53b8c8bcb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Profile the forward pass. What is the maximum of memory used? Deduce the memory size of activations. [2 points]\n",
    "\n",
    "*In notebooks, variables are kept in memory between 2 cells execution. Be careful about that when executing a cell twice!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f66693676c31b58d10fb1a247a899a5f",
     "grade": true,
     "grade_id": "cell-463f6195be063b91",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "x = torch.randn(batch_size, 3, 224, 224, device = device)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69918fb8fb82653c7e8dec7435e4088a",
     "grade": false,
     "grade_id": "cell-6f7418a5ac7ca281",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Say you want to train this model using the Adam optimizer.\n",
    "- How much memory will be used at maximum with batch size 1? [1 point]\n",
    "- What is the maximum batch size that will fit on your gpu? [1 point]\n",
    "- Try to run a training iteration. Is the actual memory usage close to your estimations? [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c416f9553a0b16bb57e88a1202cb211e",
     "grade": true,
     "grade_id": "cell-674bfb5c436f0bc9",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de8a542ae24a8b43043176d6a0722bce",
     "grade": true,
     "grade_id": "cell-69f83518746a0331",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
